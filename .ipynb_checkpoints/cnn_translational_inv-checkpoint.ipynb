{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import clear_output\n",
    "from ipywidgets import interact\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./../../data/images/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting ./../../data/images/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./../../data/images/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./../../data/images/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets('./../../data/images/mnist/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN = 55000\n",
    "IMG = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9: [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.] region: [[ 0.59375  0.71875]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD+CAYAAAAalrhRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nR4G7eAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5cb85ab7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def random_pair():\n",
    "    idx = np.random.randint(TRAIN)\n",
    "    digit = data.train.images[idx].reshape((28,28))\n",
    "    label = data.train.labels[idx].astype(np.float32)\n",
    "    \n",
    "    # Place image in random position\n",
    "    img = np.zeros((IMG, IMG), dtype=np.float32)\n",
    "    i, j = np.random.randint(IMG-28), np.random.randint(IMG-28)\n",
    "    img[i:i+28,j:j+28] = digit\n",
    "    \n",
    "    region = np.array([[float(i+14)/IMG, float(j+14)/IMG]])\n",
    "    \n",
    "    return img, label, region\n",
    "\n",
    "def random_batch(batch):\n",
    "    bi = []\n",
    "    bl = []\n",
    "    br = []\n",
    "    for i in range(batch):\n",
    "        img, label, region = random_pair()\n",
    "        img = img.reshape(IMG ** 2)\n",
    "        label = label.reshape(10)\n",
    "        bi.append(img)\n",
    "        bl.append(label)\n",
    "        br.append(region)\n",
    "    return bi, bl, br\n",
    "    \n",
    "img, label, region = random_pair()\n",
    "\n",
    "def render_region(img, region):\n",
    "    rgb = np.empty((IMG, IMG, 3), dtype=img.dtype)\n",
    "    rgb[:,:,0] = img[:,:]\n",
    "    rgb[:,:,1] = img[:,:]\n",
    "    rgb[:,:,2] = img[:,:]\n",
    "    \n",
    "    ri, rj = int(np.clip(region[0, 0], 0, 1) * IMG), int(np.clip(region[0, 1], 0, 1) * IMG)\n",
    "    rgb[ri-14:ri+14, rj-14:rj+14, 0] = np.ones((28, 28))\n",
    "    return rgb\n",
    "    \n",
    "\n",
    "print('{}: {} region: {}'.format(np.argmax(label), label, region))\n",
    "f = plt.imshow(render_region(img, region), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, IMG ** 2))\n",
    "y_ = tf.placeholder(tf.float32, (None, 10))\n",
    "y_region_ = tf.placeholder(tf.float32, [None, 1, 2])\n",
    "\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x, (-1, IMG, IMG, 1))\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "\n",
    "# Fully connected layer\n",
    "\n",
    "W_fc1 = weight_variable([32 * 32 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 32 * 32 * 64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "# Region regression\n",
    "\n",
    "W_region_fc1 = weight_variable([32 * 32 * 64, 1024])\n",
    "b_region_fc1 = bias_variable([1024])\n",
    "\n",
    "h_region_fc1 = tf.nn.tanh(tf.matmul(h_pool2_flat, W_region_fc1) + b_region_fc1)\n",
    "\n",
    "W_region_fc2 = weight_variable([1024, 2])\n",
    "b_region_fc2 = bias_variable([2])\n",
    "\n",
    "y_region = tf.matmul(h_region_fc1, W_region_fc2) + b_region_fc2\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n",
    "\n",
    "loss = cross_entropy + tf.reduce_sum(tf.square(y_region - y_region_))\n",
    "\n",
    "train = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'session' in globals():\n",
    "    session.close()\n",
    "    \n",
    "session = tf.InteractiveSession()\n",
    "session.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, classification accuracy 0.14\n",
      "step 100, classification accuracy 0.3\n",
      "step 200, classification accuracy 0.2\n",
      "step 300, classification accuracy 0.24\n",
      "step 400, classification accuracy 0.24\n",
      "step 500, classification accuracy 0.28\n",
      "step 600, classification accuracy 0.2\n",
      "step 700, classification accuracy 0.46\n",
      "step 800, classification accuracy 0.38\n",
      "step 900, classification accuracy 0.2\n",
      "step 1000, classification accuracy 0.3\n",
      "step 1100, classification accuracy 0.3\n",
      "step 1200, classification accuracy 0.38\n",
      "step 1300, classification accuracy 0.34\n",
      "step 1400, classification accuracy 0.48\n",
      "step 1500, classification accuracy 0.36\n",
      "step 1600, classification accuracy 0.42\n",
      "step 1700, classification accuracy 0.4\n",
      "step 1800, classification accuracy 0.52\n",
      "step 1900, classification accuracy 0.62\n",
      "step 2000, classification accuracy 0.56\n",
      "step 2100, classification accuracy 0.64\n",
      "step 2200, classification accuracy 0.54\n",
      "step 2300, classification accuracy 0.74\n",
      "step 2400, classification accuracy 0.6\n",
      "step 2500, classification accuracy 0.76\n",
      "step 2600, classification accuracy 0.8\n",
      "step 2700, classification accuracy 0.88\n",
      "step 2800, classification accuracy 0.72\n",
      "step 2900, classification accuracy 0.86\n",
      "step 3000, classification accuracy 0.78\n",
      "step 3100, classification accuracy 0.74\n",
      "step 3200, classification accuracy 0.8\n",
      "step 3300, classification accuracy 0.84\n",
      "step 3400, classification accuracy 0.8\n",
      "step 3500, classification accuracy 0.84\n",
      "step 3600, classification accuracy 0.86\n",
      "step 3700, classification accuracy 0.94\n",
      "step 3800, classification accuracy 0.82\n",
      "step 3900, classification accuracy 0.9\n",
      "step 4000, classification accuracy 0.96\n",
      "step 4100, classification accuracy 0.92\n",
      "step 4200, classification accuracy 0.88\n",
      "step 4300, classification accuracy 0.92\n",
      "step 4400, classification accuracy 0.94\n",
      "step 4500, classification accuracy 0.9\n",
      "step 4600, classification accuracy 0.94\n",
      "step 4700, classification accuracy 0.88\n",
      "step 4800, classification accuracy 0.88\n",
      "step 4900, classification accuracy 0.9\n",
      "step 5000, classification accuracy 0.92\n",
      "step 5100, classification accuracy 0.9\n",
      "step 5200, classification accuracy 0.9\n",
      "step 5300, classification accuracy 0.92\n",
      "step 5400, classification accuracy 0.92\n",
      "step 5500, classification accuracy 0.9\n",
      "step 5600, classification accuracy 0.92\n",
      "step 5700, classification accuracy 0.9\n",
      "step 5800, classification accuracy 0.96\n",
      "step 5900, classification accuracy 0.92\n",
      "step 6000, classification accuracy 0.98\n",
      "step 6100, classification accuracy 0.9\n",
      "step 6200, classification accuracy 0.94\n",
      "step 6300, classification accuracy 0.88\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-9d03b265e0ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"step %d, classification accuracy %g\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_region_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#print(\"classification accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jon/miniconda3/envs/mlenv2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m   1375\u001b[0m         \u001b[0mnone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m     \"\"\"\n\u001b[1;32m-> 1377\u001b[1;33m     \u001b[0m_run_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jon/miniconda3/envs/mlenv2/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[1;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3130\u001b[0m                        \u001b[1;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3131\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 3132\u001b[1;33m   \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jon/miniconda3/envs/mlenv2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;33m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m`\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mdoesn\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mexist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \"\"\"\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpartial_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jon/miniconda3/envs/mlenv2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    509\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m     results = self._do_run(handle, target_list, unique_fetches,\n\u001b[1;32m--> 511\u001b[1;33m                            feed_dict_string)\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[1;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jon/miniconda3/envs/mlenv2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 564\u001b[1;33m                            target_list)\n\u001b[0m\u001b[0;32m    565\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/jon/miniconda3/envs/mlenv2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    569\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStatusNotOK\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m       \u001b[0me_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me_traceback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jon/miniconda3/envs/mlenv2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(20000):\n",
    "    bi, bl, br = random_batch(50)\n",
    "    \n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x: bi, y_: bl, y_region_: br, keep_prob: 1.0})\n",
    "        print(\"step %d, classification accuracy %g\"%(i, train_accuracy))\n",
    "        \n",
    "    train.run(feed_dict={x: bi, y_: bl, y_region_: br, keep_prob: 0.5})\n",
    "\n",
    "#print(\"classification accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(session, './model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[-2.91269636 -2.33883119]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-c99a63b89e6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_region\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrender_region\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mri\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIMG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_region\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-5-d98fc3ea31ac>\u001b[0m in \u001b[0;36mrender_region\u001b[1;34m(img, region)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mrgb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mrgb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mri\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mri\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrj\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mrj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "# See what the model has to say!\n",
    "\n",
    "ri, rl, rr = random_pair()\n",
    "\n",
    "fd = {x:[ri.reshape((IMG ** 2))], keep_prob: 1.0}\n",
    "\n",
    "model_class = y_conv.eval(fd)[0]\n",
    "model_region = y_region.eval(fd)[0]\n",
    "\n",
    "print(np.argmax(model_class))\n",
    "\n",
    "print(model_region)\n",
    "\n",
    "f = plt.imshow(render_region(ri.reshape((IMG, IMG)), model_region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
